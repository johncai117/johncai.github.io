{"data":{"featured":{"edges":[{"node":{"frontmatter":{"title":"Cross-Domain Few-Shot Learning","cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='250'%20viewBox='0%200%20400%20250'%20preserveAspectRatio='none'%3e%3cpath%20d='M0%2017v16h401V0H0v17m0%2022c0%203%20400%203%20401%200%200-2%200-2-200-2S0%2037%200%2039m341%2041v4h14v-8h-14v4M51%2079l3%201h-1l-1%201c1%202%2018%202%2019%201l-2-2h-3l6-1c5%200%206%200%206%202l1%201a248%20248%200%20018%200h-1l-1-1h-3l-3-1%205-1%205%201v1h1c0-3%209-3%209%200l1%203v-5h29a1535%201535%200%2000-78%200m296%208l-4%201h-4l-1%206v7h20V88h-5l-4-1-1-1-1%201m-123%201v7l1%206h19V87h-10l-10%201m31%206v7h19V87h-19v7m31-6l-1%207v6h18V88l-9-1-8%201m26%206v7h17V87h-17v7m-88%2021v7l1%206h19v-14h-10l-10%201m31%206v7h19v-14h-19v7m30%200v6h18v-13h-18v7m27%200v6h17v-13h-17v7m26%200v6h20v-13h-20v7M48%20231l55%201a585%20585%200%20000-2l-55%201M0%20244v6h401v-13H0v7'%20fill='%2364ffda'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.6055045871559632,"src":"/static/86c9943fcdf1c3cc8952a24e458e9150/73c85/cdfsl2.png","srcSet":"/static/86c9943fcdf1c3cc8952a24e458e9150/d4144/cdfsl2.png 175w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/a5370/cdfsl2.png 350w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/73c85/cdfsl2.png 700w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/4ff95/cdfsl2.png 1050w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/54967/cdfsl2.png 1400w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/96d01/cdfsl2.png 2880w","srcWebp":"/static/86c9943fcdf1c3cc8952a24e458e9150/47203/cdfsl2.webp","srcSetWebp":"/static/86c9943fcdf1c3cc8952a24e458e9150/5575a/cdfsl2.webp 175w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/8ea22/cdfsl2.webp 350w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/47203/cdfsl2.webp 700w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/565e9/cdfsl2.webp 1050w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/9592d/cdfsl2.webp 1400w,\n/static/86c9943fcdf1c3cc8952a24e458e9150/4fb18/cdfsl2.webp 2880w","sizes":"(max-width: 700px) 100vw, 700px"}}},"tech":["Python","PyTorch","Torchvision","Computer Vision"],"github":"https://github.com/johncai117/Meta-Fine-Tuning","external":"https://arxiv.org/abs/2005.10544"},"html":"<p>2nd Place for CVPR 2020 Cross-Domain Few-Shot Learning (CDFSL) Challenge. Oral Presentation at CVPR VL3 Workshop.</p>\n<p>Trained a novel deep neural network to classify satellite, agricultural and medical images by successfully generalizing using only a few images. Adapts and combines a first-order Model-Agnostic Meta-Learning (MAML) algorithm with a Graph Neural Network (GNN) to learn how to fine-tune. Data augmentation and ensemble methods are incorporated to improve generalization during transfer learning.</p>"}},{"node":{"frontmatter":{"title":"Visual Question Answering","cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='225'%20viewBox='0%200%20400%20225'%20preserveAspectRatio='none'%3e%3cpath%20d='M15%2067v36h76V31H15v36m86%200v36h77V31h-77v36m117-14l-1%2036%201%2014h36c35%200%2036%200%2036-2s-1-2-5-2c-5%200-5%200-5-2l-1-4c0-2%201-2%204-2h5l-1-4c0-5-1-7-1-3l-1%203-1-7%201-5%201-2h-1c-1%201-2%200-3-2l-1-1-1-1%201-1c1%200%202-3%201-5s-12-5-17-4c-4%200-5%200-7-2v-2c1%201%202%200%201-5l1-6%201%201c0%202%2015%204%2016%202v-6h-9l-8%201-2%201-2-1v-2h2l2-2c2-1%203-4%200-5l-3-1h-13c1%201-3%201-10-1h-4v7l-2%2018-1%209v7c-1%204%200%206%203%206%205%200%207%201%207%203s-10%203-12%201c-1-2-2-1-3%200V57c0-26%200-26-2-26s-2%201-2%2022m52-20v3c-1%202%200%204%202%203h2l4%201%204-1h1c0%202%201%202%203%202s3-1%203-5c0-5%200-5-2-5s-3%201-3%202l-1%201-1-1c0-2-1-2-6-2-4%200-5%200-6%202m37%205c0%206%200%207%202%208l1%201c-2%200-2%201-2%205a2892%202892%200%20011%2021v1c-2%200-3%2028-1%2028l37%201h36V31h-26v9c0%207%201%2010%202%2012%203%204%202%205-2%205s-4%200-3-1v-1h-3c-1-1%200-2%202-2%201-1%202-1%201-2l-1-2c0-4%200-4-2-3l-3%202c-1%201-1%201-1-3s0-5%202-4l2%202c1%201%201%201%201-1l-1-2-1-3c1-1%201-1%202%201s1%201%201-2v-4l-22-1h-22v7M18%2038l1%203%201-1v-1%204l-1%203c0%202%200%202%204%201l12-3-1-1h-3c-2-1-2-1%202-1%202%200%203%200%202-1l-1-1-2-1-3%201v1l-1%201-3-2-2-1c-2%200-2%200-2-2l-1-2c-2-1-2%200-2%203m22-3l1%202c4%207%205%2013%202%2017l-1%208c0%204%200%204-4%208-5%203-5%203-6%201l-2-3c-3-1-7-6-6-8v-2l-1-1%203-1c2%200%203%200%203-2%200-1%200-2-2-2l-2%202-1-1h-2l-1-1c-1-2-1-2-1%200l-1%204-1%2012c0%2010%200%2011%201%208%202-2%205-5%208-5l1%207c1%207%201%206%203-2l2-2c2%201%202%201%202%2011%200%205%200%205%201%204l10-22c0-2%2010-1%2011%201l2%205c1%203%201%203%202%201s1-2%206-1c6%200%206%201%205%204l1%202v2c-3%202-8%201-11-1-3-4-3-4-4%200v14c2%202%203%201%203-1l2-4v2l-1%204-1%203c0%202%200%202%203-1l4-4%201-1c2-1%202-5%200-4l-2-2%202-1c1%201%207-3%207-4v-1l1-6c0-5%201-6%203-9%203-3%205-10%204-11l-4%202c-4%202-4%202-7%200l-2-1-2%201c-4%200-5%206%200%209%203%203-1%206-6%205-3-1-3-3-1-5l2-5%201-5%201-4c0-1%201-2%203-2%209-2%2012-6%205-7l-3-2-1-3-2-3H54l-14%201m193%2012l-1%207c0%203%200%203%204%203h6l3-2%204-1c2-2%202-2%200-2-2%201-4-1-4-5%200-3%200-3-4-3h-6c-2-1-2%200-2%203m-116%205c0%204-1%206-6%205-4%200-4%200-4%203%200%205%201%207%203%206l1%201%201%202%207%2010%2010%2013v-2c-1-2%202-9%204-9l1-1%202%201%204%203%202%206h1c2-1%202-2%201-5-3-8-4-13-3-18%200-5%200-5-1-4-1%202-3%202-7%202l-6%201c0%201%204%202%207%201%203%200%204%202%201%203-2%201-3%202-3%206v3l-14-9v-5l1%202c0%202%200%202%201%201l1-3%201-4%201-6c2-2%202-2%200-4-2-3-4-2-3%200h-1c-2-2-2-2-2%201m147%2012v12c2%200%203-2%203-4s0-2%202-2l3-2c0-1%201-2%203-1s2%201%201%203c-2%202%200%208%203%207l2-1%201-1-1-2-2-1c1-3-6-9-10-8-1%201-1%201%200%200l-1-1h-2c-2-1-2-1-2%201m65%2010l-3%205c0%202%202%204%203%203l5%201%202%202c-2%201%204%205%207%204l2-1-5-5c-1%200-1-1%201-1v-1l-2-1-4-1c-2%200-3%200-2-1l4-1c2%201%203%200%204-1s0-2-4-3l-5-2-3%203m26%2011l-5%206c-3%206-3%206-11%201l-6-3c1%202%2013%2012%2015%2012%203%200%2014-9%2015-13%202-4-5-6-8-3M18%20150l1%2010v3h7l7%201v1c2%200%206%2017%204%2021-1%201-1%201-1-3%200-3%200-4-1-2%200%202%200%203-2%202l-5-1-4-1c0-2-2-1-2%202-1%201-1%201-1-2l-1-5a91%2091%200%2000-1%2026l1%202%201-1%201-1c1%201%200%204-2%204-1%201-2%202-2%205l1%205h67v-20c0-18%200-20-1-17l-2%203v-6l-1%203-1%201c0-1-1-2-4-2l-5-1c0-2-2-1-5%202-1%201-2%202-3%201h-1v4h-4c-2-2-4-2-4-1-1%201-1%200-1-2s-1-1-1%204l-1%207v-8l1-8%201-4c-1-2%200-3%201-2%207%202%209%201%205-3-2-2-2-3-1-3l1-1c0-2%2012-3%2015-1l6%201%205%201v-20H18v6m85%2030v36h67v-4a191%20191%200%2000-6-44l-1-5c-2-1-3-7-3-13v-6h-57v36m118-35l-2%201c-2%200-2%200-1%201%204%201%202%202-3%202h-4l5%201%205%201h-5l-4%201-1%208c0%208%200%208%202%208l9-1-1%203%201%204v3c-2%200-4%206-3%207l1%205c0%204-2%204-5%200-2-3-4-4-4-1l1%201c3%200%203%204%201%204-1%201-2%201-1%203%200%202%201%203%202%202l1%201%204%201c5%200%207%201%204%203-2%201-3%201-5-1-4-2-7-1-7%202%200%202%200%202%209%202l13%201%2016%202%2016%202c5%203%2012%202%2010-2%200-2%204-3%209-2l7%202h4v-65h-29c-27%200-28%200-28%202s-1%202-8%202c-8%201-10-1-2-1l5-1h-5l-5-1-2-1v1m88%207v10c0%201%200%202%202%202l2%201%202%201%202%201h-5c-3%200-3%200-3%204v4h6c7%201%2017-2%2020-5l4-2%205%202c3%201%204%203%201%202-5-1-7%200-7%202s1%203%203%201l5-1c5-1%206%200%206%203l-12%204c-7%201-9%203-2%202%208%200%2013-3%2016-7%201-3%203-4%203-3l2%201v2h-4c-2%202-1%203%201%205%202%201%206%200%206-3l1-1%201%202c0%202%202%203%205%202l1%201-2%201-4%202-3%202-1%202-8%201c-6%200-8%200-5%201s3%202%202%206c-1%202-2%202-3%201l-6-2c-4%200-6-1-7-3l-3-2-1-1%202-1c6%202%207%202%2010%200l5-3%203-1-5-1-9%201-3%201-2%202c-2%201-2%200-1-1%200-2-1-2-4-2l-1-1v-1l2-1c0-3-5-1-7%203l-4%204c-3%200-1%204%203%204%204%201%204%203%200%203-9-1-9-1-9%207%200%203%200%206%201%205%201-4%203-5%209-5%204%200%205-1%206-2%202-2%202-2%203-1%204%203%203%200-1-3l-3-5%202%201c2%202%2011%205%2013%205h1l-1%201c-1%201-1%201%201%201l2%201v3c1%202%201%202-2%201l-3%201c1%201-1%202-6%202l-12%203c-6%203-5%204%202%202%206-2%208-2%204%200l-3%202%2030%201h30v-71l-37-1h-36v8m24%203c-2%200-3%201-4%203-3%204-2%205%200%204l5%202c2%202%205%203%206%201l2-1%201%201v1l2%201c2%202%202%202%205-2l5-3c1%200%200-3-2-3-1-1-3%200-4%201l-8%202-5%201-1-1c-3-3-2-4%201-4l3-1h1l3%202-1-2-4-3-5%201m-86%207l-11%202c-8%200-8%200-5%203l1%204%201%203c1%200%206%206%206%208-1%201%204%203%206%202l10-1%208-1-3-1-3-1h-1c-1%201-8%202-10%201l5-1%205-1a267%20267%200%2000-5-17h-4M45%20189c0%203%200%203-2%203s-3%202-1%208v5l-1-5-1-6-2-2c-2%200-2%201-2%203l5%2011%201%202%201%201%201-1c-1%200%200-2%202-3l2-2%204-11h-3c-3%200-3%200-3-3l-1-4v4'%20fill='%2364ffda'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.7857142857142858,"src":"/static/feb6d9f0e5e29c84b8690c43162a883b/9a128/vqa.jpg","srcSet":"/static/feb6d9f0e5e29c84b8690c43162a883b/7d800/vqa.jpg 175w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/89f4f/vqa.jpg 350w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/9a128/vqa.jpg 700w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/9a763/vqa.jpg 1050w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/f2e3f/vqa.jpg 1400w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/887f5/vqa.jpg 2667w","srcWebp":"/static/feb6d9f0e5e29c84b8690c43162a883b/47203/vqa.webp","srcSetWebp":"/static/feb6d9f0e5e29c84b8690c43162a883b/5575a/vqa.webp 175w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/8ea22/vqa.webp 350w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/47203/vqa.webp 700w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/565e9/vqa.webp 1050w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/9592d/vqa.webp 1400w,\n/static/feb6d9f0e5e29c84b8690c43162a883b/054dc/vqa.webp 2667w","sizes":"(max-width: 700px) 100vw, 700px"}}},"tech":["Python","PyTorch","FastText","Computer Vision","Natural Language Processing"],"github":"https://github.com/johncai117/VQA-Project","external":"https://www.academia.edu/44232933/Visual_Question_Answering_using_LSTM_and_ResNet"},"html":"<p>The goal of visual question answering is to train a model to be able to answer questions on a given image. To do so, the deep learning model must jointly reason over both language + vision.</p>\n<p>Used a pre-trained FastText model to extract word embeddings from the questions followed by a bi-directional LSTM to convert the sentences into sentence vectors. Applied a ResNet101 model to extract image features, and combined the image and sentence vectors into another neural network.</p>"}},{"node":{"frontmatter":{"title":"Engineering Barrier Options in C++","cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='224'%20viewBox='0%200%20400%20224'%20preserveAspectRatio='none'%3e%3cpath%20d='M290%2055c-1%203%207%204%209%201h1l3%201h5l3%201h2l3-1h2l1-1h1c1%202%208%202%208%200v-2c0-1-37-1-38%201m7%2018c0%202%200%202%201%201h27c1%202%202%201%202-1-1-2-2-2-6-2h-22c0-2-2-1-2%202m-3%207h-5c-3%200-5%202-4%204%202%201%2027%200%2028-1h1l1%201c2-2%200-4-3-4h-9l-2%201h-1c0-2-4-2-6-1m51%200l-4%201-3%201%201%202%201-2%201%201c1%202%201%202%203%201h1l1-2c1-2%201-2%201%200s3%203%203%201h1l1%201h14l1-1h4c1%202%203%202%203%201l-1-1-1-1-1-2h-1l-11%201-11-1-1-1-2%201m-40%2011c0%202%200%202%201%201h1c1%202%206%202%207%200%201-1%201%200%201%201%200%202%200%202%201%201%201-2%203-2%204-1l3-1h2c0-1%201-1%202%201s2%202%202%201l6-1%204-1c0-1%201-1%201%201%202%201%202%201%202-1s-1-3-2-3h-20l-1%202-1-1h-1l-3-1h-3l-2%201-2-1-1-1-1%203m19%2041c-1%201%200%202%205%203%202%200%203-1%203-2h1l4%201h6c1-2%201-2%201%200s2%203%203%201h2l2-2h1c0%203%202%202%202%200%200-3%200-3-8-2a3659%203659%200%2001-22%201m-43%2035c-3%203-2%204%204%204%205%200%206-1%205-2v-1l1%201c1%202%2023%202%2024%201s1-1%201%201h2c2-3%201-3-3-5h-4l-4%201-4-1h-1l-7%201h-9l-1-1c0-2-3-1-4%201M1%20210l-1%208c0%205%200%206%202%206l2-2c0-2%201-2%202-2l1%202%201%202%201-2c0-2%201-2%202-2l1%202%201%202%201-1h1l193%201h193v-15l-200-1c-182%200-200%200-200%202'%20fill='%2364ffda'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.7857142857142858,"src":"/static/b9015f1f96446846c3aaeb18491baae7/73c85/pde.png","srcSet":"/static/b9015f1f96446846c3aaeb18491baae7/d4144/pde.png 175w,\n/static/b9015f1f96446846c3aaeb18491baae7/a5370/pde.png 350w,\n/static/b9015f1f96446846c3aaeb18491baae7/73c85/pde.png 700w,\n/static/b9015f1f96446846c3aaeb18491baae7/4ff95/pde.png 1050w,\n/static/b9015f1f96446846c3aaeb18491baae7/54967/pde.png 1400w,\n/static/b9015f1f96446846c3aaeb18491baae7/3a306/pde.png 2190w","srcWebp":"/static/b9015f1f96446846c3aaeb18491baae7/47203/pde.webp","srcSetWebp":"/static/b9015f1f96446846c3aaeb18491baae7/5575a/pde.webp 175w,\n/static/b9015f1f96446846c3aaeb18491baae7/8ea22/pde.webp 350w,\n/static/b9015f1f96446846c3aaeb18491baae7/47203/pde.webp 700w,\n/static/b9015f1f96446846c3aaeb18491baae7/565e9/pde.webp 1050w,\n/static/b9015f1f96446846c3aaeb18491baae7/9592d/pde.webp 1400w,\n/static/b9015f1f96446846c3aaeb18491baae7/d0ee6/pde.webp 2190w","sizes":"(max-width: 700px) 100vw, 700px"}}},"tech":["C++","Armadillo","XLW","Financial Engineering"],"github":"https://github.com/johncai117/Pricing-Barrier-Options","external":"https://www.academia.edu/44228698/Pricing_barrier_options_using_PDEs_in_C_"},"html":"<p>Implemented both an exact pricer using a continuous analytic formula and a Partial Differential Equation pricer using C++. Modified the alignment method for the PDE estimation, and found that the fully implicit scheme has smoother convergence compared to the Crank-Nicholson scheme. Applied the Broadie-Glasserman-Kou adjustment formula, which improved convergence of the PDE pricer.</p>"}},{"node":{"frontmatter":{"title":"Event-driven Stock Price Prediction","cover":{"childImageSharp":{"fluid":{"tracedSVG":"data:image/svg+xml,%3csvg%20xmlns='http://www.w3.org/2000/svg'%20width='400'%20height='251'%20viewBox='0%200%20400%20251'%20preserveAspectRatio='none'%3e%3cpath%20d='M0%2034v33h401V0H0v34m11%20127v44h175v-89H11v45m1%200v43h173v-87H12v44'%20fill='%2364ffda'%20fill-rule='evenodd'/%3e%3c/svg%3e","aspectRatio":1.5909090909090908,"src":"/static/294eb9ec3408026094d0a16055f8fcc7/73c85/nlp.png","srcSet":"/static/294eb9ec3408026094d0a16055f8fcc7/d4144/nlp.png 175w,\n/static/294eb9ec3408026094d0a16055f8fcc7/a5370/nlp.png 350w,\n/static/294eb9ec3408026094d0a16055f8fcc7/73c85/nlp.png 700w,\n/static/294eb9ec3408026094d0a16055f8fcc7/4ff95/nlp.png 1050w,\n/static/294eb9ec3408026094d0a16055f8fcc7/54967/nlp.png 1400w,\n/static/294eb9ec3408026094d0a16055f8fcc7/75091/nlp.png 1794w","srcWebp":"/static/294eb9ec3408026094d0a16055f8fcc7/47203/nlp.webp","srcSetWebp":"/static/294eb9ec3408026094d0a16055f8fcc7/5575a/nlp.webp 175w,\n/static/294eb9ec3408026094d0a16055f8fcc7/8ea22/nlp.webp 350w,\n/static/294eb9ec3408026094d0a16055f8fcc7/47203/nlp.webp 700w,\n/static/294eb9ec3408026094d0a16055f8fcc7/565e9/nlp.webp 1050w,\n/static/294eb9ec3408026094d0a16055f8fcc7/9592d/nlp.webp 1400w,\n/static/294eb9ec3408026094d0a16055f8fcc7/76288/nlp.webp 1794w","sizes":"(max-width: 700px) 100vw, 700px"}}},"tech":["Python","PyTorch","FastText","OpenIE","NLTK","Natural Language Processing"],"github":null,"external":"https://www.academia.edu/42103229/Event_driven_Stock_Price_Prediction_using_Convolutional_Neural_Networks_for_Natural_Language_Processing"},"html":"<p>Implemented state-of-the-art methods in event extraction and natural language processing in order to predict stock price movements from news. Extracted event tuples from news articles using Open IE, and used FastText to obtain word embeddings. Applied a deep Convolutional Neural Network to capture interactions between short-term and long-term events, and obtained an improvement over previous methods.</p>"}}]}}}